# NCAR HPC
work with NCAR HPC systems to train and implement machine learning models using RNNs on Derecho or Casper nodes.

## Log Into NCAR HPC Systems

1. Use SSH to log into NCAR HPC systems:
`ssh zluo@derecho.hpc.ucar.edu`
2. Casper -> data processing and certain ML workloads.

## Submit Simple Jobs to Rachel or Casper

Submit jobs to Derecho nodes using PBS scheduling -> `job_test`:

```
#!/glade/u/apps/opt/conda/envs/npl/bin/python
#PBS -N hello_pbs
#PBS -A UCOR0090
#PBS -j oe
#PBS -k eod
#PBS -q main
#PBS -l walltime=00:05:00
#PBS -l select=1:ncpus=128:mpiprocs=128

import sys
print("Hello, world!!\n\n From a deep learning class at Cornell")

print("Python version:")
print(sys.version)
print("Version info:")
print(sys.version_info)
```

1. Submit -> `qsub job_test`   
2. Monitor submission -> `qstat -u zluo`   
3. Check for output and debug files generated by job in the working directory.

## Use NCAR HPC Jupyter Hub

Access NCAR HPC systems interactively using the Jupyter Hub:

1. https://jupyterhub.hpc.ucar.edu/
2. log in

## Upload and Download Files

Transfer scripts, datasets, or results to/from NCAR HPC systems.

* Upload -> `scp local_file zluo@derecho.hpc.ucar.edu://glade/u/home/zluo`
* Download -> `scp zluo@derecho.hpc.ucar.edu:glade/u/home/zluo local_file`

## Edit Scripts Remotely

Use tools like Vim, Nano, or VS Code for remote editing directly:

* edit scripts with Vim -> `vim xx.py`
* Connect Visual Studio Code to NCAR HPC systems using the Remote SSH extension: https://code.visualstudio.com/docs/remote/ssh

## Monitor Resource Usage

Keep tabs on core hours usage and active jobs:

* Check current jobs: `qstat -u your_username`
* View core hours: `ncar_accounting_report`

## Clone Repository

git clone https://github.com/bnulzq/DL.git






